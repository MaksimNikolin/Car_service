{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaksimNikolin/Carservice/blob/main/object_detection_yolov7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G2sXJ_oq-yT"
      },
      "source": [
        "## *Unpacking the archive with the dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzlRhZ0Xso_-",
        "outputId": "d566bcef-b9b2-420c-897a-0fc467c12503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #connect to GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMboBKRwrJ2M",
        "outputId": "6ee32dcb-d7ae-4dad-d9aa-28593c3cbd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "#unpacking training and validation datasets\n",
        "%cd /content\n",
        "!unzip -q /content/drive/MyDrive/Colab_Notebooks/object_detection_carservice/dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyHSGXwxhRuI"
      },
      "source": [
        "## *Cloning the repository*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azu5nxGkhVTa",
        "outputId": "7182c2b8-5b80-49ff-dc14-06d814b23987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1191, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 1191 (delta 2), reused 6 (delta 2), pack-reused 1185\u001b[K\n",
            "Receiving objects: 100% (1191/1191), 74.23 MiB | 33.60 MiB/s, done.\n",
            "Resolving deltas: 100% (511/511), done.\n"
          ]
        }
      ],
      "source": [
        "save_to_drive = False\n",
        "\n",
        "if save_to_drive:\n",
        "     %cd /content/drive/MyDrive\n",
        "else:\n",
        "     %cd /content\n",
        "\n",
        "!git clone https://github.com/WongKinYiu/yolov7 #cloning the model from the site"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWIIy23IhwuP"
      },
      "source": [
        "## *Loading suggested weights or using our own weights*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9ouwOjohmIF"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n",
        "weight_path = 'yolov7-tiny.pt'\n",
        "#weight_path = '/content/drive/MyDrive/yolov7-tiny.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcmNVreUh38I"
      },
      "outputs": [],
      "source": [
        "#paths to folders with training and validation datasets, and class names\n",
        "train_path = '/content/train'\n",
        "val_path = '/content/valid'\n",
        "classes = ['person','car','plate']\n",
        "\n",
        "str_classes = ','.join(classes)\n",
        "data_text = [f'train: {train_path}',\n",
        "         f'val: {val_path}',\n",
        "         f'nc: {len(classes)}',\n",
        "         f'names: [{str_classes}]']\n",
        "data_text = '\\n'.join(data_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSzQ_93JiVkP"
      },
      "outputs": [],
      "source": [
        "if save_to_drive:\n",
        "    path_to_yolo7 = '/content/drive/MyDrive/yolov7'\n",
        "else:\n",
        "    path_to_yolo7 = '/content/yolov7'\n",
        "\n",
        "with open(f'{path_to_yolo7}/data/custom_data.yaml', 'w') as f:\n",
        "    f.write(data_text)\n",
        "\n",
        "with open(f'{path_to_yolo7}/cfg/training/yolov7-tiny.yaml') as f:\n",
        "    cfg_text = f.readlines()\n",
        "\n",
        "cfg_text[1] = f'nc: {len(classes)} # number of classes\\n'\n",
        "with open(f'{path_to_yolo7}/cfg/training/yolov7-tiny_custom.yaml', 'w') as f:\n",
        "    cfg_text = f.writelines(cfg_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eQE07atKqA1"
      },
      "source": [
        "## *Launching training*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHtSTwNVieJS",
        "outputId": "f7f56dc0-4399-42f0-c68c-db6aa837fb78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "2023-07-11 15:46:28.760181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-11 15:46:29.669801: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "YOLOR 🚀 v0.1-126-g84932d7 torch 2.0.1+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='yolov7-tiny.pt', cfg='cfg/training/yolov7-tiny_custom.yaml', data='data/custom_data.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=51, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=4, project='runs/train', entity=None, name='test4', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/test4', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt to yolov7-tiny.pt...\n",
            "100% 12.1M/12.1M [00:00<00:00, 122MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            "  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  8                -1  1         0  models.common.MP                        []                            \n",
            "  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 15                -1  1         0  models.common.MP                        []                            \n",
            " 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 22                -1  1         0  models.common.MP                        []                            \n",
            " 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 31                -1  1         0  models.common.SP                        [5]                           \n",
            " 32                -2  1         0  models.common.SP                        [9]                           \n",
            " 33                -3  1         0  models.common.SP                        [13]                          \n",
            " 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 36          [-1, -7]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 41          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 59          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
            " 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 67          [-1, 37]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 77      [74, 75, 76]  1     22544  models.yolo.IDetect                     [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 263 layers, 6020400 parameters, 6020400 gradients\n",
            "\n",
            "Transferred 330/344 items from yolov7-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 58 .bias, 58 conv.weight, 61 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels' images and labels... 39 found, 0 missing, 0 empty, 0 corrupted:   2% 39/2042 [00:00<00:05, 371.93it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MDRfMDZfMjAyM18xMl80NF8wNF83NzQyOTQ.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels' images and labels... 250 found, 0 missing, 0 empty, 1 corrupted:  12% 250/2042 [00:00<00:02, 649.96it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MDdfMDZfMjAyM18xM18wMF8xM18wMzA2NzU.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MDdfMDZfMjAyM18xM18wMV8zNF8zMzk0ODU.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MDdfMDZfMjAyM18xM18wMl8wMV85MzYwNjk.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels' images and labels... 452 found, 0 missing, 0 empty, 4 corrupted:  22% 452/2042 [00:00<00:01, 1138.16it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MTFfMDZfMjAyM18xMV80MF80MF83MDU3NTk.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MTFfMDZfMjAyM18xMV80MV8wMF83MTc0NDQ.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MTFfMDZfMjAyM18xMV8zNl81NV8xODc0MTg.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels' images and labels... 784 found, 0 missing, 0 empty, 7 corrupted:  38% 784/2042 [00:00<00:00, 1872.93it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MTJfMDZfMjAyM18xMl81NF81OF81MDE1MjQ.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MTJfMDZfMjAyM18xMl81OF8wN18zNjQ2NTU.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MTJfMDZfMjAyM18xMl8zM18zMl8wODc0MDc.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjRfMDVfMjAyM18xMl80M18wOV81MDYyMzI.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjRfMDVfMjAyM18xMl80M18zMV83ODE1NDc.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels' images and labels... 1102 found, 0 missing, 0 empty, 12 corrupted:  54% 1102/2042 [00:00<00:00, 2297.67it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjRfMDVfMjAyM18xMl80NF8xNF8yMzE2ODY.jpeg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjRfMDVfMjAyM18xMl81MF8yMV83NDY0MTA.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjRfMDVfMjAyM18xMl81MV8xMV83NDc1NzU.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjRfMDVfMjAyM18xMl81MV8xOV8yODAyMzU.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjRfMDVfMjAyM18xMl81Ml80N18wNTY3MDY.jpeg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels' images and labels... 1441 found, 0 missing, 0 empty, 17 corrupted:  71% 1441/2042 [00:00<00:00, 2643.07it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjRfMDVfMjAyM18xMl8zMl8wM182OTQ1NTQ.jpeg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjVfMDVfMjAyM18wOF8xM18yMF81MjY4MjU.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/MjVfMDVfMjAyM18wOF8xM18zNF81MTM4Nzc.jpeg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/blur.gen.MTJfMDZfMjAyM18xMl8zM18zMl8wODc0MDc.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/blur.gen.MjRfMDVfMjAyM18xMl80NF8xNF8yMzE2ODY.jpeg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/grayscale.gen.MDRfMDZfMjAyM18xMl80NF8wNF83NzQyOTQ.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/grayscale.gen.MDdfMDZfMjAyM18xM18wMl8wMV85MzYwNjk.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels' images and labels... 1732 found, 0 missing, 0 empty, 24 corrupted:  85% 1732/2042 [00:00<00:00, 2724.35it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/grayscale.gen.MTJfMDZfMjAyM18xMl81NF81OF81MDE1MjQ.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/noise.gen.MjRfMDVfMjAyM18xMl80M18wOV81MDYyMzI.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/part_0.brightness.gen.MjRfMDVfMjAyM18xMl81MF8yMV83NDY0MTA.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/train/images/part_1.brightness.gen.MjRfMDVfMjAyM18xMl81MF8yMV83NDY0MTA.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels' images and labels... 2042 found, 0 missing, 0 empty, 28 corrupted: 100% 2042/2042 [00:01<00:00, 2015.58it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train/labels.cache\n",
            "Scanning images:   0% 0/458 [00:00<?, ?it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/valid/images/MDZfMDZfMjAyM18wOF8wM18wOF82MDkxNTc.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/valid/images/MDZfMDZfMjAyM18wOF8wM18xMl8zMDM1MjA.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/valid/images/MDZfMDZfMjAyM18xM180M18yM18yMTI3OTE.jpeg: duplicate labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/valid/images/MDZfMDZfMjAyM18xM180M18yMF83MzMxMTQ.jpeg: duplicate labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/valid/images/MDhfMDZfMjAyM18xMF80NV80OF83Mjg5NjQ.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/valid/labels' images and labels... 198 found, 0 missing, 0 empty, 5 corrupted:  43% 198/458 [00:00<00:00, 1979.35it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/valid/images/MjRfMDVfMjAyM18xMl80Nl8zOV8yNjE0ODY.jpeg: duplicate labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/valid/images/MjRfMDVfMjAyM18xMl81M18zNV82MDY3NjY.jpeg: duplicate labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/valid/images/MjVfMDVfMjAyM18wOF8xMl81M18xOTU3NDM.jpeg: negative labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/valid/labels' images and labels... 458 found, 0 missing, 0 empty, 8 corrupted: 100% 458/458 [00:00<00:00, 2095.47it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.06, Best Possible Recall (BPR) = 0.9846\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/test4\n",
            "Starting training for 51 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/50    0.554G   0.07392   0.02444   0.01658    0.1149       205       640: 100% 126/126 [05:29<00:00,  2.61s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:24<00:00,  1.65s/it]\n",
            "                 all         450        3146         0.8       0.408       0.412        0.16\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/50     2.64G   0.05753   0.02083  0.005316   0.08368       214       640: 100% 126/126 [04:55<00:00,  2.35s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.36s/it]\n",
            "                 all         450        3146       0.758       0.481       0.466       0.168\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/50     2.85G   0.04847   0.01941  0.003823   0.07171       182       640: 100% 126/126 [04:55<00:00,  2.35s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:19<00:00,  1.31s/it]\n",
            "                 all         450        3146       0.689         0.7       0.671       0.335\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/50     2.85G   0.04037   0.01793  0.002846   0.06114       174       640: 100% 126/126 [04:51<00:00,  2.31s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.45s/it]\n",
            "                 all         450        3146       0.949       0.756        0.85       0.553\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/50     2.85G   0.03828   0.01738  0.002301   0.05796       189       640: 100% 126/126 [04:53<00:00,  2.33s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:19<00:00,  1.30s/it]\n",
            "                 all         450        3146       0.938       0.802       0.864       0.555\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/50     2.85G   0.03237   0.01649  0.001553   0.05042       266       640: 100% 126/126 [04:45<00:00,  2.27s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.41s/it]\n",
            "                 all         450        3146       0.955       0.785       0.875       0.592\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/50     2.85G   0.03092   0.01574  0.001199   0.04786       281       640: 100% 126/126 [04:47<00:00,  2.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.35s/it]\n",
            "                 all         450        3146       0.972       0.835       0.899       0.594\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/50     2.85G   0.02938   0.01566  0.001025   0.04607       224       640: 100% 126/126 [04:50<00:00,  2.30s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:19<00:00,  1.28s/it]\n",
            "                 all         450        3146       0.977       0.872       0.905       0.622\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/50     2.85G   0.02744   0.01501 0.0008531    0.0433       161       640: 100% 126/126 [05:01<00:00,  2.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.46s/it]\n",
            "                 all         450        3146       0.943       0.881       0.917       0.653\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/50     2.85G   0.02561   0.01448 0.0006823   0.04077       191       640: 100% 126/126 [05:05<00:00,  2.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:25<00:00,  1.67s/it]\n",
            "                 all         450        3146       0.958        0.88       0.919       0.649\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/50     2.85G   0.02462   0.01415  0.000646   0.03941       223       640: 100% 126/126 [04:54<00:00,  2.33s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.42s/it]\n",
            "                 all         450        3146       0.983       0.861        0.93       0.672\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/50     2.85G   0.02416   0.01423 0.0005687   0.03896       216       640: 100% 126/126 [04:55<00:00,  2.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:23<00:00,  1.55s/it]\n",
            "                 all         450        3146        0.96       0.899       0.931       0.651\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/50     2.85G   0.02317   0.01397 0.0005686    0.0377       198       640: 100% 126/126 [05:01<00:00,  2.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.41s/it]\n",
            "                 all         450        3146       0.969       0.907       0.934       0.683\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/50     2.85G   0.02244   0.01395 0.0004913   0.03688       219       640: 100% 126/126 [04:58<00:00,  2.37s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.36s/it]\n",
            "                 all         450        3146       0.978       0.901       0.927       0.704\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/50     2.85G   0.02179   0.01354 0.0004761    0.0358       153       640: 100% 126/126 [05:01<00:00,  2.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.45s/it]\n",
            "                 all         450        3146       0.969       0.924       0.947       0.706\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/50     2.85G   0.02131   0.01359 0.0005098    0.0354       199       640: 100% 126/126 [04:57<00:00,  2.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.46s/it]\n",
            "                 all         450        3146       0.973       0.914       0.946       0.699\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/50     2.85G   0.02132   0.01378 0.0005194   0.03561       203       640: 100% 126/126 [05:01<00:00,  2.40s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:19<00:00,  1.31s/it]\n",
            "                 all         450        3146       0.976       0.925        0.95       0.707\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/50     2.85G   0.02068   0.01358 0.0004616   0.03472       246       640: 100% 126/126 [04:57<00:00,  2.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.38s/it]\n",
            "                 all         450        3146       0.965        0.92       0.949       0.713\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/50     2.85G   0.02033   0.01342 0.0004358   0.03418       220       640: 100% 126/126 [04:57<00:00,  2.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:22<00:00,  1.48s/it]\n",
            "                 all         450        3146        0.98       0.908       0.949       0.722\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/50     2.85G   0.01996   0.01323 0.0003968   0.03359       219       640: 100% 126/126 [04:58<00:00,  2.37s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:22<00:00,  1.53s/it]\n",
            "                 all         450        3146       0.971        0.91       0.937       0.711\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/50     2.85G   0.01958   0.01295 0.0004175   0.03295       197       640: 100% 126/126 [04:49<00:00,  2.30s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:19<00:00,  1.28s/it]\n",
            "                 all         450        3146       0.968       0.919       0.948       0.717\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/50     2.85G   0.01901   0.01301 0.0003844    0.0324       206       640: 100% 126/126 [04:57<00:00,  2.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:19<00:00,  1.32s/it]\n",
            "                 all         450        3146       0.969       0.929        0.95        0.73\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/50     2.85G   0.01904   0.01291 0.0003676   0.03232       222       640: 100% 126/126 [04:54<00:00,  2.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:19<00:00,  1.33s/it]\n",
            "                 all         450        3146        0.97       0.934       0.949       0.722\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/50     2.85G   0.01851   0.01274 0.0003448    0.0316       226       640: 100% 126/126 [04:55<00:00,  2.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:18<00:00,  1.25s/it]\n",
            "                 all         450        3146       0.984       0.925       0.952       0.733\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/50     2.85G   0.01854   0.01263 0.0003676   0.03154       220       640: 100% 126/126 [04:48<00:00,  2.29s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.44s/it]\n",
            "                 all         450        3146        0.98       0.931       0.954       0.727\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/50     2.85G   0.01827   0.01265 0.0003431   0.03126       252       640: 100% 126/126 [04:49<00:00,  2.29s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:17<00:00,  1.15s/it]\n",
            "                 all         450        3146       0.981       0.927       0.954       0.732\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/50     2.85G   0.01792   0.01242  0.000357   0.03069       227       640: 100% 126/126 [04:47<00:00,  2.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:22<00:00,  1.50s/it]\n",
            "                 all         450        3146       0.983       0.922       0.951       0.739\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/50     2.85G   0.01752   0.01222 0.0003137   0.03005       150       640: 100% 126/126 [04:54<00:00,  2.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.34s/it]\n",
            "                 all         450        3146       0.989       0.899       0.946       0.731\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/50     2.85G   0.01749   0.01229 0.0002869   0.03007       199       640: 100% 126/126 [04:52<00:00,  2.32s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:17<00:00,  1.18s/it]\n",
            "                 all         450        3146       0.975       0.924        0.95       0.734\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/50     2.85G   0.01738   0.01222 0.0003079   0.02992       200       640: 100% 126/126 [04:59<00:00,  2.38s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.38s/it]\n",
            "                 all         450        3146       0.976       0.917       0.943       0.732\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/50     2.85G   0.01706   0.01194  0.000327   0.02933       283       640: 100% 126/126 [04:46<00:00,  2.27s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:18<00:00,  1.27s/it]\n",
            "                 all         450        3146       0.984       0.927       0.952       0.734\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/50     2.85G   0.01694   0.01221  0.000331   0.02948       210       640: 100% 126/126 [04:48<00:00,  2.29s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.40s/it]\n",
            "                 all         450        3146       0.984       0.927       0.954       0.738\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/50     2.85G   0.01686   0.01218 0.0002988   0.02933       232       640: 100% 126/126 [04:51<00:00,  2.31s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:18<00:00,  1.24s/it]\n",
            "                 all         450        3146       0.986       0.932       0.958       0.747\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/50     2.85G   0.01675   0.01182  0.000286   0.02886       206       640: 100% 126/126 [04:54<00:00,  2.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.35s/it]\n",
            "                 all         450        3146       0.981       0.929       0.954       0.744\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/50     2.85G   0.01661   0.01197 0.0002614   0.02885       216       640: 100% 126/126 [04:52<00:00,  2.32s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:22<00:00,  1.50s/it]\n",
            "                 all         450        3146       0.975       0.921        0.95       0.743\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/50     2.85G   0.01651   0.01186 0.0002548   0.02863       216       640: 100% 126/126 [04:46<00:00,  2.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:22<00:00,  1.47s/it]\n",
            "                 all         450        3146       0.968       0.943       0.955       0.747\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/50     2.85G   0.01641   0.01181 0.0002759   0.02849       202       640: 100% 126/126 [04:48<00:00,  2.29s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.36s/it]\n",
            "                 all         450        3146       0.966       0.937       0.951       0.746\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/50     2.85G   0.01631   0.01178 0.0002981   0.02839       240       640: 100% 126/126 [04:55<00:00,  2.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:16<00:00,  1.10s/it]\n",
            "                 all         450        3146       0.979       0.928       0.957       0.751\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/50     2.85G   0.01606   0.01169 0.0002739   0.02803       241       640: 100% 126/126 [04:53<00:00,  2.33s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.46s/it]\n",
            "                 all         450        3146       0.979       0.925       0.955       0.752\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/50     2.85G   0.01617   0.01135 0.0003123   0.02784       191       640: 100% 126/126 [04:51<00:00,  2.31s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.40s/it]\n",
            "                 all         450        3146       0.976       0.933       0.958        0.75\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/50     2.85G   0.01599   0.01157 0.0002886   0.02785       198       640: 100% 126/126 [05:00<00:00,  2.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:22<00:00,  1.49s/it]\n",
            "                 all         450        3146       0.973        0.94       0.959       0.753\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/50     2.85G   0.01592   0.01158 0.0002727   0.02777       216       640: 100% 126/126 [05:14<00:00,  2.50s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.41s/it]\n",
            "                 all         450        3146       0.984        0.93       0.956       0.754\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/50     2.85G   0.01596   0.01156 0.0002858    0.0278       209       640: 100% 126/126 [05:10<00:00,  2.46s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:21<00:00,  1.46s/it]\n",
            "                 all         450        3146       0.971       0.936       0.957       0.751\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/50     2.85G   0.01578   0.01139 0.0002499   0.02743       233       640: 100% 126/126 [04:44<00:00,  2.26s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.37s/it]\n",
            "                 all         450        3146       0.978       0.936       0.956       0.758\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/50     2.85G   0.01587   0.01138 0.0002671   0.02751       247       640: 100% 126/126 [04:50<00:00,  2.31s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:18<00:00,  1.21s/it]\n",
            "                 all         450        3146       0.974       0.932       0.953       0.754\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     45/50     2.85G   0.01581   0.01146 0.0002638   0.02753       265       640: 100% 126/126 [04:47<00:00,  2.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:19<00:00,  1.27s/it]\n",
            "                 all         450        3146        0.97        0.94       0.957       0.755\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/50     2.85G   0.01566   0.01133 0.0002513   0.02724       186       640: 100% 126/126 [04:47<00:00,  2.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:20<00:00,  1.35s/it]\n",
            "                 all         450        3146       0.978        0.93       0.956       0.756\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/50     2.85G   0.01574   0.01126 0.0002454   0.02724       188       640: 100% 126/126 [04:45<00:00,  2.26s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:19<00:00,  1.30s/it]\n",
            "                 all         450        3146       0.977       0.933       0.956       0.755\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/50     2.85G   0.01565   0.01134 0.0002855   0.02728       219       640: 100% 126/126 [04:53<00:00,  2.33s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:22<00:00,  1.49s/it]\n",
            "                 all         450        3146       0.968       0.941       0.956       0.756\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/50     2.85G   0.01557   0.01143 0.0002751   0.02727       220       640: 100% 126/126 [04:49<00:00,  2.29s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:17<00:00,  1.16s/it]\n",
            "                 all         450        3146       0.962       0.943       0.956       0.754\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     50/50     2.85G   0.01561   0.01148 0.0002808   0.02737       230       640: 100% 126/126 [04:51<00:00,  2.31s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 15/15 [00:25<00:00,  1.67s/it]\n",
            "                 all         450        3146       0.968       0.938       0.953       0.755\n",
            "              person         450        1287       0.986       0.979       0.976        0.87\n",
            "                 car         450         802       0.954       0.906       0.936       0.618\n",
            "               plate         450        1057       0.965       0.927       0.948       0.777\n",
            "51 epochs completed in 4.487 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/test4/weights/last.pt, 12.3MB\n",
            "Optimizer stripped from runs/train/test4/weights/best.pt, 12.3MB\n"
          ]
        }
      ],
      "source": [
        "model_name = 'test4' #if it gives errors that it cannot find the image along the path, then it is necessary to delete the cache files\n",
        "\n",
        "if save_to_drive:\n",
        "    %cd /content/drive/MyDrive/yolov7\n",
        "else:\n",
        "    %cd /content/yolov7/\n",
        "\n",
        "!python train.py --workers 4 --device 0 --batch-size 16 --epochs 51 --data data/custom_data.yaml \\\n",
        "                 --img 640 640 --cfg cfg/training/yolov7-tiny_custom.yaml --weights $weight_path \\\n",
        "                 --name $model_name --hyp data/hyp.scratch.custom.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMEoNCg8Eurj",
        "outputId": "f5a1bf9f-2b27-4efb-9824-aea467c91ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx) (1.22.4)\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.1 protobuf-3.20.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (1.7.1)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.3.3)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.1\n"
          ]
        }
      ],
      "source": [
        "#installing the libraries necessary to run the model\n",
        "!pip install -q onnx\n",
        "!pip install -q onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPTyeb3ZDqHv"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/yolov7/runs/train/ppc1/weights/best.pt' #path to training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc0UTU1sC5Sn",
        "outputId": "0ef9e06d-26c4-4d09-d5e9-a6178f21fad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov7\n",
            "Import onnx_graphsurgeon failure: No module named 'onnx_graphsurgeon'\n",
            "Namespace(weights='/content/yolov7/runs/train/ppc1/weights/best.pt', img_size=[224, 416], batch_size=1, dynamic=False, dynamic_batch=False, grid=True, end2end=True, max_wh=0, topk_all=100, iou_thres=0.3, conf_thres=0.3, device='0', simplify=True, include_nms=False, fp16=False, int8=False)\n",
            "YOLOR 🚀 v0.1-122-g3b41c2c torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "IDetect.fuse\n",
            "Model Summary: 208 layers, 6013008 parameters, 0 gradients\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "Starting TorchScript export with torch 1.13.1+cu116...\n",
            "/content/yolov7/models/yolo.py:150: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "TorchScript export success, saved as /content/yolov7/runs/train/ppc1/weights/best.torchscript.pt\n",
            "CoreML export failure: No module named 'coremltools'\n",
            "\n",
            "Starting TorchScript-Lite export with torch 1.13.1+cu116...\n",
            "TorchScript-Lite export success, saved as /content/yolov7/runs/train/ppc1/weights/best.torchscript.ptl\n",
            "\n",
            "Starting ONNX export with onnx 1.13.1...\n",
            "onnxruntime\n",
            "/content/yolov7/models/experimental.py:108: FutureWarning: 'torch.onnx._patch_torch._graph_op' is deprecated in version 1.13 and will be removed in version 1.14. Please note 'g.op()' is to be removed from torch.Graph. Please open a GitHub issue if you need this functionality..\n",
            "  return g.op(\"NonMaxSuppression\", boxes, scores, max_output_boxes_per_class, iou_threshold, score_threshold)\n",
            "/usr/local/lib/python3.9/dist-packages/torch/onnx/symbolic_opset9.py:5408: UserWarning: Exporting aten::index operator of advanced indexing in opset 12 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  warnings.warn(\n",
            "Simplifier failure: No module named 'onnxsim'\n",
            "ONNX export success, saved as /content/yolov7/runs/train/ppc1/weights/best.onnx\n",
            "\n",
            "Export complete (12.24s). Visualize with https://github.com/lutzroeder/netron.\n"
          ]
        }
      ],
      "source": [
        "if save_to_drive:\n",
        "    %cd /content/drive/MyDrive/yolov7\n",
        "else:\n",
        "    %cd /content/yolov7\n",
        "\n",
        "#for onnxruntime, you need to specify this value as an integer, when it is 0 it means agnostic NMS, otherwise it is non-agnostic NMS\n",
        "!python export.py --weights $model_path --grid --end2end --simplify \\\n",
        "                  --device 0 --topk-all 100 --iou-thres 0.3 \\\n",
        "                  --conf-thres 0.3 --img-size 224 416 --max-wh 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxJDzNh9sEb7"
      },
      "source": [
        "## *Model testing*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-_P9FBuTOXq"
      },
      "outputs": [],
      "source": [
        "#copy files from validation folder to testing folder\n",
        "from posixpath import basename\n",
        "import shutil\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "os.mkdir('/content/test_imgs')\n",
        "for _ in range(10):\n",
        "    img_path = np.random.choice(glob.glob(f'{val_path}/images/*'))\n",
        "    filename = os.path.basename(img_path)\n",
        "    dest_path = f'/content/test_imgs/{filename}'\n",
        "    print(dest_path)\n",
        "    shutil.copy(img_path, dest_path)\n",
        "    #print(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-rnE2eQJZ93"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict, namedtuple\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "cuda = True\n",
        "\n",
        "w = '/content/yolov7/runs/train/ppc1/weights/best.onnx'  #path to converted model from a cell with conversion\n",
        "inp_w = 416 #permission to enter the converted model\n",
        "inp_h = 224\n",
        "names = ['car','person','plate'] #class names\n",
        "SCORE_THRESH = 0.5\n",
        "\n",
        "test_folder = '/content/test_imgs' #folder with testing pics\n",
        "\n",
        "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
        "session = ort.InferenceSession(w, providers=providers)\n",
        "\n",
        "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
        "    #resize and pad image while meeting stride-multiple constraints\n",
        "    shape = im.shape[:2]  #current shape [height, width]\n",
        "    if isinstance(new_shape, int):\n",
        "        new_shape = (new_shape, new_shape)\n",
        "\n",
        "    #scale ratio (new/old)\n",
        "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
        "    if not scaleup:  #only scale down, do not scale up (for better val mAP)\n",
        "        r = min(r, 1.0)\n",
        "\n",
        "    #compute padding\n",
        "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
        "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  #wh padding\n",
        "\n",
        "    if auto:  #minimum rectangle\n",
        "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  #wh padding\n",
        "\n",
        "    dw /= 2  #divide padding into 2 sides\n",
        "    dh /= 2\n",
        "\n",
        "    if shape[::-1] != new_unpad:  #resize\n",
        "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
        "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
        "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
        "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  #add border\n",
        "    return im, r, (dw, dh)\n",
        "\n",
        "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFJR5gAyJghY"
      },
      "outputs": [],
      "source": [
        "for img_path in glob.glob(f'{test_folder}/*'):\n",
        "    img = cv2.imread(img_path)[246:960, 260:1590]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image = img.copy()\n",
        "    image = cv2.resize(image, (inp_w, inp_h))\n",
        "    image = image.transpose((2, 0, 1))\n",
        "    image = np.expand_dims(image, 0)\n",
        "    image = np.ascontiguousarray(image)\n",
        "\n",
        "    im = image.astype(np.float32)\n",
        "    im /= 255\n",
        "    im.shape\n",
        "\n",
        "    outname = [i.name for i in session.get_outputs()]\n",
        "    inname = [i.name for i in session.get_inputs()]\n",
        "\n",
        "    inp = {inname[0]:im}\n",
        "\n",
        "    #ONNX inference\n",
        "    outputs = session.run(outname, inp)[0]\n",
        "    outputs\n",
        "\n",
        "    ori_images = [img.copy()]\n",
        "\n",
        "    for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
        "        if score < SCORE_THRESH:\n",
        "            break\n",
        "        image = ori_images[int(batch_id)]\n",
        "        x0 = int(x0 / inp_w * img.shape[1])\n",
        "        y0 = int(y0 / inp_h * img.shape[0])\n",
        "        x1 = int(x1 / inp_w * img.shape[1])\n",
        "        y1 = int(y1 / inp_h * img.shape[0])\n",
        "        cls_id = int(cls_id)\n",
        "        score = round(float(score),3)\n",
        "        name = names[cls_id]\n",
        "        color = colors[name]\n",
        "        name += ' ' + str(score)\n",
        "        cv2.rectangle(img,(x0,y0),(x1,y1),color,2)\n",
        "        cv2.putText(img,name,(x0, y0 - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2)\n",
        "    plt.figure(figsize=(15,10))\n",
        "    plt.imshow(img)\n",
        "    #Image.fromarray(ori_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I_tSM9hDje1"
      },
      "outputs": [],
      "source": [
        "#loading the weights of the model and the converted model file\n",
        "from google.colab import files\n",
        "files.download(model_path)\n",
        "files.download(w)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
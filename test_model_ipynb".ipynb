{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaksimNikolin/Carservice/blob/main/test_model_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBjP2NB5G0Xq",
        "outputId": "8ed9f77b-7aa6-4079-89bc-7f2cb2d13101"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.14.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.11.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import functions\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def seconds_to_m_s(seconds):\n",
        "    m = int(seconds // 60)\n",
        "    s = int(seconds % 60)\n",
        "    return m, s\n",
        "\n",
        "\n",
        "def preprocess_input(img, input_w, input_h):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    image = img.copy()\n",
        "    image = cv2.resize(image, (input_w, input_h))\n",
        "    image = image.transpose((2, 0, 1))\n",
        "    image = np.expand_dims(image, 0)\n",
        "    image = np.ascontiguousarray(image)\n",
        "    im = image.astype(np.float32)\n",
        "    im /= 255\n",
        "    return im\n",
        "\n",
        "\n",
        "def detect_all(image, sessions, innames, outnames, inputs_w, inputs_h, SCORE_THRESH, shift_classes):\n",
        "    bboxes = []\n",
        "    for idx, (session, inname, outname, input_w, input_h, thresh) in enumerate(zip(sessions,\n",
        "                                                                               innames,\n",
        "                                                                               outnames,\n",
        "                                                                               inputs_w,\n",
        "                                                                               inputs_h,\n",
        "                                                                               SCORE_THRESH)):\n",
        "        im = preprocess_input(image, input_w, input_h)\n",
        "        inp = {inname[0]: im}\n",
        "        outputs = session.run(outname, inp)[0]\n",
        "        for i, (batch_id, x0, y0, x1, y1, cls_id, score) in enumerate(outputs):\n",
        "            if score > thresh:\n",
        "                x0 = int(x0 / input_w * image.shape[1])\n",
        "                y0 = int(y0 / input_h * image.shape[0])\n",
        "                x1 = int(x1 / input_w * image.shape[1])\n",
        "                y1 = int(y1 / input_h * image.shape[0])\n",
        "                bboxes.append([shift_classes[idx] + int(cls_id), x0, y0, x1, y1])\n",
        "    return bboxes\n",
        "\n",
        "\n",
        "def prepare_classes(classes):\n",
        "    start_pos = [0] * len(classes)\n",
        "    class_names = classes[0]\n",
        "    for i in range(1, len(classes)):\n",
        "        start_pos[i] = start_pos[i-1] + len(classes[i-1])\n",
        "        class_names += classes[i]\n",
        "    return start_pos, class_names\n",
        "\n",
        "\n",
        "def get_all_classes(boxes, start_pos):\n",
        "    for i in range(len(boxes)):\n",
        "        model_idx, label = boxes[i][4]\n",
        "        class_id = start_pos[model_idx] + label\n",
        "        boxes[i][4] = class_id\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def detect(image, session, inname, outname, input_w, input_h, SCORE_THRESH):\n",
        "    bboxes = []\n",
        "    labels = []\n",
        "    im = preprocess_input(image, input_w, input_h)\n",
        "    inp = {inname[0]: im}\n",
        "    outputs = session.run(outname, inp)[0]\n",
        "    for i, (batch_id, x0, y0, x1, y1, cls_id, score) in enumerate(outputs):\n",
        "        if score > SCORE_THRESH:\n",
        "            x0 = int(x0 / input_w * image.shape[1])\n",
        "            y0 = int(y0 / input_h * image.shape[0])\n",
        "            x1 = int(x1 / input_w * image.shape[1])\n",
        "            y1 = int(y1 / input_h * image.shape[0])\n",
        "            bboxes.append([int(cls_id), x0, y0, x1, y1])\n",
        "    return bboxes\n",
        "\n",
        "\n",
        "def create_xml_file(folder, path, file_name, all_boxes):\n",
        "    return f'''<?xml version=\"1.0\" ?>\n",
        "<annotation>\n",
        "    <folder>{folder}</folder>\n",
        "    <filename>{file_name}</filename>\n",
        "    <path>{path}</path>\n",
        "    <source>\n",
        "        <database>Unknown</database>\n",
        "    </source>\n",
        "    <segmented>0</segmented>\n",
        "    {all_boxes}\n",
        "</annotation>'''\n",
        "\n",
        "\n",
        "def create_xml_box(class_name, box):\n",
        "    xmin,ymin,xmax,ymax = box\n",
        "    box_form = f'''<object>\n",
        "    <name>{class_name}</name>\n",
        "    <pose>Unspecified</pose>\n",
        "    <truncated>0</truncated>\n",
        "    <difficult>0</difficult>\n",
        "    <bndbox>\n",
        "        <xmin>{xmin}</xmin>\n",
        "        <ymin>{ymin}</ymin>\n",
        "        <xmax>{xmax}</xmax>\n",
        "        <ymax>{ymax}</ymax>\n",
        "    </bndbox>\n",
        "</object>'''\n",
        "    return box_form\n",
        "\n",
        "\n",
        "def get_boxes_xml(image, bboxes, class_names, use_xml=True, draw_box=True):\n",
        "    points = []\n",
        "    all_boxes_form = ''\n",
        "    for i, box in enumerate(bboxes):\n",
        "        points.append(box)\n",
        "        xmin = int(max(box[1],0))\n",
        "        ymin = int(max(box[2],0))\n",
        "        xmax = int(min(box[3],image.shape[1]))\n",
        "        ymax = int(min(box[4], image.shape[0]))\n",
        "        class_id = int(box[0])\n",
        "        box = (xmin, ymin, xmax, ymax)\n",
        "        if use_xml:\n",
        "            box_form = create_xml_box(class_names[class_id], box)\n",
        "            all_boxes_form += box_form\n",
        "        if draw_box:\n",
        "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "    return all_boxes_form, points\n",
        "\n",
        "\n",
        "def xml_to_boxes(xml_file):\n",
        "    tree = ET.parse(open(xml_file))\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "    for object in root.iter('object'):\n",
        "        box_form = object.find('bndbox')\n",
        "        xmin = int(box_form.find('xmin').text)\n",
        "        ymin = int(box_form.find('ymin').text)\n",
        "        xmax = int(box_form.find('xmax').text)\n",
        "        ymax = int(box_form.find('ymax').text)\n",
        "        boxes.append((xmin, ymin, xmax, ymax))\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def start_processing_time():\n",
        "    start_time_hms = datetime.datetime.now()\n",
        "    print('Work started in {}:{:02d}:{:02d}'.format(start_time_hms.hour, start_time_hms.minute, start_time_hms.second))\n",
        "    return time.time()\n",
        "\n",
        "\n",
        "def calculated_left_time(total_save, start_pocessing, frame_ind, serial_number, frame_ind_load):\n",
        "    pass_images = int((frame_ind - frame_ind_load) / serial_number)\n",
        "    left_images = total_save - int(frame_ind / serial_number)\n",
        "    if left_images > 0:\n",
        "        left_time_sec = int((time.time() - start_pocessing) * left_images / pass_images)\n",
        "        print('It remains to process the images:', left_images)\n",
        "        left_time = datetime.timedelta(seconds=left_time_sec)\n",
        "        print('It will take:', str(left_time))\n",
        "        finish_time = datetime.datetime.now() + left_time\n",
        "        print('Approximately processing will end in {}:{:02d}:{:02d}'.format(finish_time.hour, finish_time.minute, finish_time.second))"
      ],
      "metadata": {
        "id": "u73Shd9SHTps"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MPbbHylzGFwQ"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import shutil\n",
        "import onnxruntime as ort\n",
        "import glob\n",
        "import numpy as np\n",
        "from string import ascii_lowercase\n",
        "#from tools.utils import (detect, seconds_to_m_s, get_boxes_xml, create_xml_file, start_processing_time, calculated_left_time)\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Create folder named 'Model_data' and put our model 'best.onnx' in it.\n",
        "Create folder named 'u1' and put unmarked images in it.*"
      ],
      "metadata": {
        "id": "KlebFBJlEFsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_work = time.time()\n",
        "\n",
        "frames_dir = 'u1' #path to the folder with input frames\n",
        "models_dir = 'Model_data' #folder for models\n",
        "model_name = 'best.onnx' #model name\n",
        "\n",
        "model_input_size = (288,512)\n",
        "input_h = model_input_size[0]\n",
        "input_w = model_input_size[1]\n",
        "\n",
        "cuda = False\n",
        "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
        "\n",
        "class_names = ['car','person','plate'] #label names\n",
        "SCORE_THRESH = 0.5 #the threshold of probability below which the prediction is filtered out\n",
        "checkpoint_size = 100 #how many frames must pass before saving the checkpoint, taking into account the skipping of frames\n",
        "USE_XML = True #use as output labels: False - use only the label dictionary, True - use additional xml tags\n",
        "DRAW_BOXES = True #do I need to create test images in folder named 'Draw' with the head frames drawn\n",
        "\n",
        "\n",
        "model_path = os.path.join(models_dir, model_name)\n",
        "session = ort.InferenceSession(model_path, providers=providers)\n",
        "inname = [i.name for i in session.get_inputs()]\n",
        "outname = [i.name for i in session.get_outputs()]\n",
        "\n",
        "\n",
        "if DRAW_BOXES:\n",
        "    draw_dir = os.path.join(frames_dir, 'Draw')\n",
        "    if not os.path.exists(draw_dir):\n",
        "        os.mkdir(draw_dir)\n",
        "\n",
        "\n",
        "processing_start = start_processing_time()\n",
        "print('\\nFrames are being processed and saved...')\n",
        "all_imgs = glob.glob(frames_dir + '/*.jpeg')\n",
        "count_save = 0\n",
        "for fil in tqdm(all_imgs):\n",
        "    image = cv2.imread(fil)\n",
        "    image_name = os.path.basename(fil)\n",
        "    image_name_short = image_name.split('.')[0]\n",
        "    bboxes = np.array(detect(image, session, inname, outname, input_w, input_h, SCORE_THRESH))\n",
        "    if len(bboxes) != 0:\n",
        "        bboxes = bboxes[bboxes[:, -1] > 250]\n",
        "        all_boxes_form, points = get_boxes_xml(image, bboxes, class_names, USE_XML, DRAW_BOXES)\n",
        "        if DRAW_BOXES:\n",
        "            cv2.imwrite(os.path.join(draw_dir, image_name), image)\n",
        "        if USE_XML:\n",
        "            form_xml = create_xml_file(frames_dir, frames_dir, image_name, all_boxes_form)\n",
        "            with open(os.path.join(frames_dir, image_name_short + '.xml'), 'w') as file:\n",
        "                file.write(form_xml)\n",
        "        count_save += 1\n",
        "\n",
        "    # if count_save % checkpoint_size == 0:\n",
        "    #     print('\\nProcessed frames:', count_save)\n",
        "    #     calculated_left_time(len(all_imgs), processing_start, count_save, 1, 0)\n",
        "\n",
        "print('Frame saving completed.')\n",
        "\n",
        "duration = time.time()-start_work\n",
        "processing_duration = time.time()-processing_start\n",
        "print('\\nTotal video processing took {} minuts and {} seconds'.format(*seconds_to_m_s(duration)))\n",
        "print('More accuratelly:', round(duration, 2))\n",
        "print('Processing only:', round(processing_duration, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cIpPrigG_Qm",
        "outputId": "164ff695-3522-4303-e8de-9692a379a919"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Work started in 13:43:06\n",
            "\n",
            "Frames are being processed and saved...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame saving completed.\n",
            "\n",
            "Total video processing took 0 minuts and 0 seconds\n",
            "More accuratelly: 0.86\n",
            "Processing only: 0.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}